//4xV100s needed
{
  "dataset": "vcr",

  "rationale": false, // Doing q->a or qa->r

  "vcr_annots_dir":"/proj/vondrick/parita/projects/visualbert/X_VCR", //Please replace this with the actual corresponding folder
  "vcr_image_dir":"/proj/vondrick/parita/projects/visualbert/X_VCR/vcr1images", //Please replace this with the actual corresponding folder

  "use_fixed_feature": false,
  "image_screening_parameters": null,

  "use_alignment": true,
  "special_screen": false,
  "add_all_features": true,

  "fp16": false,
  "loss_scale": 512,

  "max_seq_length": 128,
  "bert_model_name": "bert-base-uncased",
  "do_lower_case": true,
  "train_batch_size": 48,
  "eval_batch_size":  16,

  "pretraining": false,
  "pretraining_include_qar": false, // Whether we want to include qar for pre-training
  "pretraining_include_qa_and_qar": false,
  "complete_shuffle": false,

  ////////Evlaution
  "do_test":true,
  "vcr_save_result":true,
  "skip_training": false,
  "epoch_to_load": 0,

  "patience": 3,
  "learning_rate": 2e-5,
  "num_train_epochs":  10,
  "warmup_proportion": 0.1,
  "grad_norm": 1.0,
  "gradient_accumulation_steps": 1,

  "restore_bin": "/proj/vondrick/parita/projects/visualbert/self_trained_models/mpii/mpii-pre-train-from-bert/model_state_epoch_5.th",
  "num_workers": 32,
  "val_workers": 8,

  "freeze_detector": false,

  "use_bert":  true,

  "model":
  {
    "type": "VideoBERT",
    "special_visual_initialize": true,
    "training_head_type": "multichoice",
    "visual_embedding_dim": 512
  }
}
